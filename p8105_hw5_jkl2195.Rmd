---
title: "p8105_hw5_jkl2195"
author: "Jessie Li"
date: "2023-11-02"
output: github_document
---

```{r}
library(tidyverse)
library(readr)
library(stringr)
library(purrr)
library(broom)
library(forcats)
```

## Problem 1

```{r}
df_homicide = read.csv("data/homicide-data.csv") |>
  mutate(
    city_state = str_c(city, ", ", state)
  ) |>
  select(-city, -state)

```

Number of Homicides organized by cities
```{r}
df_unsolved_homicide = df_homicide |>
  group_by(city_state) |>
  summarize(
    total_homicides = n(), 
    unsolved_homicides = 
      sum(str_detect(disposition, "without|No"))
  )
df_unsolved_homicide
```
Estimate the proportion of homicide that are unsolved in Baltimore, MD


```{r}
  prop.test(
    df_unsolved_homicide |>
    filter(city_state == "Baltimore, MD") |> 
    pull(unsolved_homicides),
    df_unsolved_homicide |>
    filter(city_state == "Baltimore, MD") |> 
    pull(total_homicides)
  ) |>
  tidy() |>
  select(estimate, conf.low, conf.high)
```

```{r}
df_unsolved_prop = df_unsolved_homicide |>
  mutate(
   estimate = map2(
    df_unsolved_homicide |>
      pull(unsolved_homicides),
    df_unsolved_homicide |>
      pull(total_homicides),
    prop.test
    ),
    estimate = map(estimate, tidy)
  ) |>
  unnest_wider(estimate) |>
  select(city_state, estimate, conf.low, conf.high)

df_unsolved_prop
```
This is a table of the proportion of unsolved homicides and the confidence interval of each.

```{r fig.height = 10, fig.width = 10}
df_unsolved_prop |>
  ggplot(aes(x = city_state, y = estimate, color = city_state)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(
    legend.position="bottom", 
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```
This is a plot of the proportion of unsolved homicides bounded by the confidence interval of each.

## Problem 2
```{r}
filenames = list.files(path = "./data", pattern = ".+[0-9].+", full.names = TRUE)

df_study = map(filenames, read.csv) |>
  bind_rows() |>
  mutate(
    group = map(filenames, str_extract, "[:alpha:]{3}(?=_)") |>
      as.character(),
    id = map(filenames, str_extract, "[:digit:]{2}") |> 
      as.numeric()
  ) |>
  pivot_longer(
    cols = week_1:week_8,
    names_to = "week",
    names_pattern = "week_(.)",
    values_to = "observation"
  )
df_study
```
Cleaned up dataset about a longitudinal study that included a control arm and an experimental arm.

```{r}
df_study |>
  group_by(group, id) |>
  ggplot(aes(x = week, y = observation, group = interaction(group, id), color = group)) +
  geom_point() + 
  geom_line()
  
```
This is a spaghetti plot of the observations on each subject over time. The rate of change for the control group is constant while the rate of change for experimental is increasing at a linear rate.

## Problem 3

```{r}
n = 30
sets = 5000
sig = 5
alp = 0.05
h0 = 0

sim_normal = function(mu, n_samp = n, sigma = sig, alpha = alp, null= h0){
  rnorm(n = n_samp, mean = mu, sd = 5) |> 
  t.test(null.value = null, conf.level = 1-alpha)
}
 
df_sim_normal = expand_grid(
    mean = 0:6,
    iter = 1:sets
  ) |>
  mutate(
    estimate = map(mean, sim_normal),
    estimate = map(estimate, tidy)
  ) |>
  unnest_wider(estimate) |>
  select(mean, iter, estimate, p.value)

df_sim_normal
```

Generated 5000 datasets with each mu 0 to 6 using randomized normal distribution where n = 30, sigma = 5. 

```{r}
df_sim_normal |>
  group_by(mean) |>
  summarize(power = sum(p.value < alp) / sets) |>
  ggplot(aes(x = mean, y = power)) +
  geom_point() +
  geom_line()
```

This is a plot the proportion of times the null was rejected (the power of the test) on the y axis and the true value of mu on the x axis. There is a positive relationship between the effect size and the power. Power stayed at 1 after reaching around mean 4.


